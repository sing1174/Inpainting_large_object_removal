{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22da1a08-2e08-4ed1-a346-bc5e2b3e58e2",
      "metadata": {
        "id": "22da1a08-2e08-4ed1-a346-bc5e2b3e58e2"
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread, imsave, imshow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from skimage.color import rgb2gray, rgb2lab\n",
        "from skimage.filters import laplace\n",
        "from scipy.ndimage import convolve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e893df65-c09e-4a61-9571-3e2130449267",
      "metadata": {
        "id": "e893df65-c09e-4a61-9571-3e2130449267"
      },
      "outputs": [],
      "source": [
        "# for plotting each iteration\n",
        "def plot_image(working_image, working_mask, front):\n",
        "    height, width = working_mask.shape\n",
        "\n",
        "    inverse_mask = 1 - working_mask\n",
        "    rgb_inverse_mask = convert_to_rgb(inverse_mask)\n",
        "    image = working_image * rgb_inverse_mask\n",
        "\n",
        "    image[:, :, 0] += front * 255\n",
        "\n",
        "    white_portion = (working_mask - front) * 255\n",
        "    rgb_white_region = convert_to_rgb(white_portion)\n",
        "    image += rgb_white_region\n",
        "\n",
        "    plt.clf()\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.draw()\n",
        "    plt.pause(0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45c4ce73-c438-45e4-a24c-db6d88681ce6",
      "metadata": {
        "id": "45c4ce73-c438-45e4-a24c-db6d88681ce6"
      },
      "outputs": [],
      "source": [
        "#function to calculate unit normal perpendicular to the front\n",
        "def calculate_normal(working_mask):\n",
        "    x_kernel = np.array([[.25, 0, -.25], [.5, 0, -.5], [.25, 0, -.25]])\n",
        "    y_kernel = np.array([[-.25, -.5, -.25], [0, 0, 0], [.25, .5, .25]])\n",
        "\n",
        "    x_normal = convolve(working_mask.astype(float), x_kernel)\n",
        "    y_normal = convolve(working_mask.astype(float), y_kernel)\n",
        "    normal = np.dstack((x_normal, y_normal))\n",
        "\n",
        "    height, width = normal.shape[:2]\n",
        "    norm = np.sqrt(y_normal**2 + x_normal**2).reshape(height, width, 1).repeat(2, axis=2)\n",
        "    norm[norm == 0] = 1\n",
        "\n",
        "    unit_normal = normal / norm\n",
        "    return unit_normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aee6d68-4e96-49ae-a2d4-d4152153d51b",
      "metadata": {
        "id": "7aee6d68-4e96-49ae-a2d4-d4152153d51b"
      },
      "outputs": [],
      "source": [
        "#Find patch of input patch_size centered at a point\n",
        "def find_patch(working_image, point, patch_size):\n",
        "    half_patch_size = (patch_size - 1) // 2\n",
        "    height, width = working_image.shape[:2]\n",
        "\n",
        "    #If patch lies at either of the image, we modify our patch accordingly\n",
        "    patch = [\n",
        "        [\n",
        "            max(0, point[0] - half_patch_size),\n",
        "            min(point[0] + half_patch_size, height - 1)\n",
        "        ],\n",
        "        [\n",
        "            max(0, point[1] - half_patch_size),\n",
        "            min(point[1] + half_patch_size, width - 1)\n",
        "        ]\n",
        "    ]\n",
        "    return patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4bc964a-a8fc-4ecc-8b59-737705a27a7c",
      "metadata": {
        "id": "d4bc964a-a8fc-4ecc-8b59-737705a27a7c"
      },
      "outputs": [],
      "source": [
        "#get pixels from the corresponding source patch\n",
        "def patch_data(source, patch):\n",
        "    return source[\n",
        "        patch[0][0]:patch[0][1] + 1,\n",
        "        patch[1][0]:patch[1][1] + 1\n",
        "    ]\n",
        "\n",
        "#find the patch shape\n",
        "def patch_shape(patch):\n",
        "    return (1+patch[0][1]-patch[0][0]), (1+patch[1][1]-patch[1][0])\n",
        "\n",
        "#find area of patch\n",
        "def patch_area(patch):\n",
        "    return (1 + patch[0][1] - patch[0][0]) * (1 + patch[1][1] - patch[1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7438bc08-a616-46a4-bd24-550ce80442b2",
      "metadata": {
        "id": "7438bc08-a616-46a4-bd24-550ce80442b2"
      },
      "outputs": [],
      "source": [
        "#Converting image to RGB\n",
        "def convert_to_rgb(image):\n",
        "    height, width = image.shape\n",
        "    return image.reshape(height, width, 1).repeat(3, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3de2951-4b3f-4aac-935d-40a9a5c73a54",
      "metadata": {
        "id": "a3de2951-4b3f-4aac-935d-40a9a5c73a54"
      },
      "outputs": [],
      "source": [
        "#function returns gradient matrix for updating data\n",
        "def calculate_gradient(working_image, working_mask, front, patch_size):\n",
        "    height, width = working_image.shape[:2]\n",
        "\n",
        "    grey_image = rgb2gray(working_image)\n",
        "    grey_image[working_mask == 1] = None\n",
        "\n",
        "    gradient = np.nan_to_num(np.array(np.gradient(grey_image)))\n",
        "    gradient_val = np.sqrt(gradient[0]**2 + gradient[1]**2)\n",
        "    max_gradient = np.zeros([height, width, 2])\n",
        "\n",
        "    front_positions = np.argwhere(front == 1)\n",
        "    for point in front_positions:\n",
        "        patch = find_patch(working_image, point, patch_size)\n",
        "        patch_y_gradient = patch_data(gradient[0], patch)\n",
        "        patch_x_gradient = patch_data(gradient[1], patch)\n",
        "        patch_gradient_val = patch_data(gradient_val, patch)\n",
        "\n",
        "        patch_max_pos = np.unravel_index(\n",
        "            patch_gradient_val.argmax(),\n",
        "            patch_gradient_val.shape\n",
        "        )\n",
        "\n",
        "        max_gradient[point[0], point[1], 0] = patch_y_gradient[patch_max_pos]\n",
        "        max_gradient[point[0], point[1], 1] = patch_x_gradient[patch_max_pos]\n",
        "\n",
        "    return max_gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab08154-7625-42ea-b0af-d7846947d8bc",
      "metadata": {
        "id": "6ab08154-7625-42ea-b0af-d7846947d8bc"
      },
      "outputs": [],
      "source": [
        "# find distance between target patch and source patch\n",
        "def patch_diff(image, working_mask, target_patch, source_patch):\n",
        "    mask = 1 - patch_data(working_mask, target_patch)\n",
        "    rgb_mask = convert_to_rgb(mask)\n",
        "    target_data = patch_data(image, target_patch) * rgb_mask\n",
        "    source_data = patch_data(image, source_patch) * rgb_mask\n",
        "    squared_distance = ((target_data - source_data)**2).sum()\n",
        "    euclidean_distance = np.sqrt(\n",
        "        (target_patch[0][0] - source_patch[0][0])**2 +\n",
        "        (target_patch[1][0] - source_patch[1][0])**2\n",
        "    )\n",
        "    return squared_distance + euclidean_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc4cc8e-ee47-4bcd-981b-8f3784123e5e",
      "metadata": {
        "id": "0fc4cc8e-ee47-4bcd-981b-8f3784123e5e"
      },
      "outputs": [],
      "source": [
        "# finding source patch to fill up target patch\n",
        "def find_source_patch(working_image, working_mask, target_pixel, patch_size):\n",
        "    target_patch = find_patch(working_image, target_pixel, patch_size)\n",
        "    height, width = working_image.shape[:2]\n",
        "    patch_height, patch_width = patch_shape(target_patch)\n",
        "\n",
        "    best_match = None\n",
        "    best_match_diff = 0\n",
        "\n",
        "    lab_image = rgb2lab(working_image)\n",
        "\n",
        "    for y in range(height - patch_height + 1):\n",
        "        for x in range(width - patch_width + 1):\n",
        "            source_patch = [\n",
        "                [y, y + patch_height-1],\n",
        "                [x, x + patch_width-1]\n",
        "            ]\n",
        "            if patch_data(working_mask, source_patch).sum() != 0:\n",
        "                continue\n",
        "\n",
        "            # Compute sum of Euclidean distance and Squared distance between patches as difference\n",
        "            diff = patch_diff(lab_image, working_mask, target_patch, source_patch)\n",
        "\n",
        "            # Select best match as the source patch that has minimum difference from target patch\n",
        "            if best_match is None or diff < best_match_diff:\n",
        "                best_match = source_patch\n",
        "                best_match_diff = diff\n",
        "    return best_match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fd0bde-7f68-472b-9378-88b967da4a74",
      "metadata": {
        "id": "75fd0bde-7f68-472b-9378-88b967da4a74"
      },
      "outputs": [],
      "source": [
        "# Updating confidence values for updated working_image and updated working_mask\n",
        "def update_confidence_value(confidence, working_image, working_mask, patch_size, target_pixel, source_patch):\n",
        "    target_patch = find_patch(working_image, target_pixel, patch_size)\n",
        "    pixels_positions = np.argwhere(\n",
        "        patch_data(\n",
        "            working_mask,\n",
        "            target_patch\n",
        "        ) == 1\n",
        "    ) + [target_patch[0][0], target_patch[1][0]]\n",
        "    patch_confidence = confidence[target_pixel[0], target_pixel[1]]\n",
        "    for point in pixels_positions:\n",
        "        confidence[point[0], point[1]] = patch_confidence\n",
        "\n",
        "    mask = patch_data(working_mask, target_patch)\n",
        "    rgb_mask = convert_to_rgb(mask)\n",
        "    source_data = patch_data(working_image, source_patch)\n",
        "    target_data = patch_data(working_image, target_patch)\n",
        "\n",
        "    new_data = source_data * rgb_mask + target_data * (1 - rgb_mask)\n",
        "\n",
        "    #Copy new data to target patch in working_image\n",
        "    working_image[\n",
        "        target_patch[0][0]:target_patch[0][1] + 1,\n",
        "        target_patch[1][0]:target_patch[1][1] + 1\n",
        "    ] = new_data\n",
        "\n",
        "    working_mask[\n",
        "        target_patch[0][0]:target_patch[0][1] + 1,\n",
        "        target_patch[1][0]:target_patch[1][1] + 1\n",
        "    ] = 0\n",
        "\n",
        "    return working_image, working_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "593da3a0-ffe9-4a7a-bbbc-60bc6854840a",
      "metadata": {
        "id": "593da3a0-ffe9-4a7a-bbbc-60bc6854840a"
      },
      "outputs": [],
      "source": [
        "# main function for inpainting\n",
        "def inpaint_image(image_path, mask_path, patch_size=13, show_progress=False):\n",
        "\n",
        "    # Read the image and mask inputs and convert them to 'uint8' datatype\n",
        "    image = imread(image_path).astype('uint8')\n",
        "    mask = imread(mask_path, as_gray=True).round().astype('uint8')\n",
        "\n",
        "    #check if image and mask are of the same shape\n",
        "    if image.shape[:2] != mask.shape:\n",
        "        raise AttributeError('Image and Mask are not of the same size!!')\n",
        "\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Confidence is initialized as the inverse of the mask (the target region is 0 and the source region is 1)\n",
        "    confidence = (1 - mask).astype(float)\n",
        "    data = np.zeros([height, width])\n",
        "\n",
        "    #working_image and working_mask are initialized as copies of input image and mask\n",
        "    working_image = np.copy(image)\n",
        "    working_mask = np.copy(mask)\n",
        "\n",
        "    continue_inpainting = True\n",
        "    i=1\n",
        "    start_time = time.time()\n",
        "\n",
        "    #continue inpainting until target region is filled\n",
        "    while continue_inpainting:\n",
        "\n",
        "        # The front or contour is found using the Laplace filter on the working_mask.\n",
        "        # Laplace gives us the edges around the target region\n",
        "        front = (laplace(working_mask) > 0).astype('uint8')\n",
        "\n",
        "        # Plotting each iteration in our algorithm\n",
        "        if show_progress:\n",
        "            plot_image(working_image, working_mask, front)\n",
        "            print(f\"Iteration {i}\")\n",
        "        # Calculate confidence values - confidence is higher for source region pixels that are near the edges of contour\n",
        "        new_data_confidence = np.copy(confidence)\n",
        "        front_positions = np.argwhere(front == 1)\n",
        "        for point in front_positions:\n",
        "            patch = find_patch(working_image, point, patch_size)\n",
        "            new_data_confidence[point[0], point[1]] = sum(sum(patch_data(confidence, patch))) / patch_area(patch)\n",
        "\n",
        "        confidence = new_data_confidence\n",
        "\n",
        "        # Calculate normal orthogonal to the front and gradient\n",
        "        normal = calculate_normal(working_mask)\n",
        "        gradient = calculate_gradient(working_image, working_mask, front, patch_size)\n",
        "\n",
        "        normal_gradient = normal * gradient\n",
        "        data = np.sqrt(normal_gradient[:, :, 0]**2 + normal_gradient[:, :, 1]**2) + 0.001\n",
        "\n",
        "        # Updating priority values - that are assigned to each patch on the fill front\n",
        "        priority = confidence * data * front\n",
        "\n",
        "        # Find the highest priority pixel\n",
        "        target_pixel = np.unravel_index(priority.argmax(), priority.shape)\n",
        "\n",
        "        find_start_time = time.time()\n",
        "\n",
        "        #Find the most similar patch to our target pixel\n",
        "        source_patch = find_source_patch(working_image, working_mask, target_pixel, patch_size)\n",
        "\n",
        "        #Update working_image, working_mask and confidence values after filling up target patch\n",
        "        working_image, working_mask = update_confidence_value(confidence, working_image, working_mask, patch_size, target_pixel, source_patch)\n",
        "\n",
        "        i+=1\n",
        "        #Check if target region has been filled completely\n",
        "        if working_mask.sum()==0:\n",
        "            continue_inpainting = False\n",
        "            print(f\"Completed in {i} iterations. Took {time.time() - start_time} seconds!!\")\n",
        "    return working_image\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uncomment these lines to check results"
      ],
      "metadata": {
        "id": "h3fBLQV8HL1V"
      },
      "id": "h3fBLQV8HL1V"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3b8233a7-2945-4b27-9a51-2f29699f6df6",
      "metadata": {
        "id": "3b8233a7-2945-4b27-9a51-2f29699f6df6"
      },
      "outputs": [],
      "source": [
        "# result1 = inpaint_image(\"jumper.jpg\", \"jumper_mask.jpg\", patch_size= 13, show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a94015ad-0258-4ae3-89c6-211aa3e2bfb5",
      "metadata": {
        "id": "a94015ad-0258-4ae3-89c6-211aa3e2bfb5"
      },
      "outputs": [],
      "source": [
        "# result2 = inpaint_image(\"baseball.jpg\", \"baseball_mask.jpg\", patch_size= 11, show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7432b734-2b6d-45a3-b67c-c87b04a93796",
      "metadata": {
        "id": "7432b734-2b6d-45a3-b67c-c87b04a93796"
      },
      "outputs": [],
      "source": [
        "# result3 = inpaint_image(\"Curved_lines.jpg\", \"Curved_lines_mask.jpg\", patch_size= 11, show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "686fa4e5-4ea1-47b6-a317-c6109f6b2d13",
      "metadata": {
        "id": "686fa4e5-4ea1-47b6-a317-c6109f6b2d13"
      },
      "outputs": [],
      "source": [
        "# result4 = inpaint_image(\"aerial.jpg\", \"aerial_mask.jpg\", patch_size= 13, show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3e099316-2460-4b68-ac36-04e15c7c93a2",
      "metadata": {
        "id": "3e099316-2460-4b68-ac36-04e15c7c93a2"
      },
      "outputs": [],
      "source": [
        "# result5 = inpaint_image(\"plus.jpg\", \"circle_mask.jpg\", patch_size= 13, show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d9baf49-5733-4bc6-9647-020e3431b0ab",
      "metadata": {
        "id": "8d9baf49-5733-4bc6-9647-020e3431b0ab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8fefc78-655f-4d8c-862a-a63bc892b668",
      "metadata": {
        "id": "b8fefc78-655f-4d8c-862a-a63bc892b668"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a893cd7-f5f0-4ec0-90f3-0a389774777f",
      "metadata": {
        "id": "2a893cd7-f5f0-4ec0-90f3-0a389774777f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}